{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLhi7WYSR1US"
      },
      "source": [
        "#Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaaRd1ZVILTo",
        "outputId": "8fabba92-f517-4589-c14e-59337a2699d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nilearn==0.9.2 in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: joblib>=0.15 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (1.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (4.9.2)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (1.5.3)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn==0.9.2) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->nilearn==0.9.2) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.9.2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.9.2) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.9.2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2->nilearn==0.9.2) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->nilearn==0.9.2) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0->nilearn==0.9.2) (1.16.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.11.1)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nilearn==0.9.2\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1OBk-m9R_Uu"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7A5A3ru9Y-R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from nilearn import datasets, plotting\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ZSavyOSLl1"
      },
      "source": [
        "#Mount to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcs-uTq39gnF",
        "outputId": "f663c814-6b65-4536-d9c6-704816a5ba66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "data_dir = '/content/drive/MyDrive/algonauts_2023_tutorial_data'\n",
        "parent_submission_dir = '/content/drive/MyDrive/algonauts_2023_challenge_submission'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KrPcW7GSN3h"
      },
      "source": [
        "#Select device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C3ruJC89jUE",
        "outputId": "c9aa6844-7103-4ee6-bc5b-b15325675c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5GZ9xqnSSNX"
      },
      "source": [
        "#Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPoAjZp9jvw"
      },
      "outputs": [],
      "source": [
        "subj = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"] {type:\"raw\", allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2umiPF29nda"
      },
      "outputs": [],
      "source": [
        "class argObj:\n",
        "  def __init__(self, data_dir, parent_submission_dir, subj):\n",
        "\n",
        "    self.subj = format(subj, '02')\n",
        "    self.data_dir = os.path.join(data_dir, 'subj'+self.subj)\n",
        "    self.parent_submission_dir = parent_submission_dir\n",
        "    self.subject_submission_dir = os.path.join(self.parent_submission_dir,\n",
        "        'subj'+self.subj)\n",
        "\n",
        "args = argObj(data_dir, parent_submission_dir, subj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_azz_FRN9rjL",
        "outputId": "d2e42d5d-8893-4a52-82f6-6a8aa92d5955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LH training fMRI data shape:\n",
            "(9841, 19004)\n",
            "(Training stimulus images × LH vertices)\n"
          ]
        }
      ],
      "source": [
        "fmri_dir = os.path.join(args.data_dir, 'training_split', 'training_fmri')\n",
        "lh_fmri = np.load(os.path.join(fmri_dir, 'lh_training_fmri.npy'))\n",
        "\n",
        "print('\\nLH training fMRI data shape:')\n",
        "print(lh_fmri.shape)\n",
        "print('(Training stimulus images × LH vertices)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yi6y52o9uOb",
        "outputId": "8961fdd8-851c-490b-fc6d-7bc58061de4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training images: 9841\n",
            "Test images: 159\n"
          ]
        }
      ],
      "source": [
        "train_img_dir  = os.path.join(args.data_dir, 'training_split', 'training_images')\n",
        "test_img_dir  = os.path.join(args.data_dir, 'test_split', 'test_images')\n",
        "\n",
        "# Create lists will all training and test image file names, sorted\n",
        "train_img_list = os.listdir(train_img_dir)\n",
        "train_img_list.sort()\n",
        "test_img_list = os.listdir(test_img_dir)\n",
        "test_img_list.sort()\n",
        "print('Training images: ' + str(len(train_img_list)))\n",
        "print('Test images: ' + str(len(test_img_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5LM6Fv0VkRF"
      },
      "source": [
        "#Train Validation and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PneuXQq9wVr",
        "outputId": "1790c4c0-cd1a-4968-d9a2-5430f004d393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training stimulus images: 8857\n",
            "\n",
            "Validation stimulus images: 984\n",
            "\n",
            "Test stimulus images: 159\n"
          ]
        }
      ],
      "source": [
        "rand_seed = 5\n",
        "np.random.seed(rand_seed)\n",
        "\n",
        "# Calculate how many stimulus images correspond to 90% of the training data\n",
        "num_train = int(np.round(len(train_img_list) / 100 * 90))\n",
        "# Shuffle all training stimulus images\n",
        "idxs = np.arange(len(train_img_list))\n",
        "np.random.shuffle(idxs)\n",
        "# Assign 90% of the shuffled stimulus images to the training partition,\n",
        "# and 10% to the test partition\n",
        "idxs_train, idxs_val = idxs[:num_train], idxs[num_train:]\n",
        "# No need to shuffle or split the test stimulus images\n",
        "idxs_test = np.arange(len(test_img_list))\n",
        "\n",
        "print('Training stimulus images: ' + format(len(idxs_train)))\n",
        "print('\\nValidation stimulus images: ' + format(len(idxs_val)))\n",
        "print('\\nTest stimulus images: ' + format(len(idxs_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmWbeAvOV2hr"
      },
      "source": [
        "#Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqbsvQqGTT23"
      },
      "outputs": [],
      "source": [
        "# Define the custom dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, imgs_paths, idxs, transform):\n",
        "        self.imgs_paths = np.array(imgs_paths)[idxs]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.imgs_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img).to(device)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7UvgeNfTgvD"
      },
      "source": [
        "#Transfer Learning and Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Dbd1DJ9z20",
        "outputId": "b2b4d0e2-d759-4327-bb2f-cfea5cca4813"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the transform for image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # resize the images to 224x224 pixels\n",
        "    transforms.ToTensor(),  # convert the images to a PyTorch tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # normalize the images color channels\n",
        "])\n",
        "\n",
        "# Remove the last layer of the pretrained model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "class LinearizingEncodingModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim1, hidden_dim2, activation1, activation2,\n",
        "                 bnorm1, bnorm2, dropout1, dropout_ratio1, dropout2, dropout_ratio2):\n",
        "        super(LinearizingEncodingModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        if activation1:\n",
        "            self.activation1 = activation1()\n",
        "        if bnorm1:\n",
        "            self.batchnorm1 = nn.BatchNorm1d(hidden_dim1)\n",
        "        if dropout1:\n",
        "            self.dropout1 = nn.Dropout(dropout_ratio1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        if activation2:\n",
        "            self.activation2 = activation2()\n",
        "        if bnorm2:\n",
        "            self.batchnorm2 = nn.BatchNorm1d(hidden_dim2)\n",
        "        if dropout2:\n",
        "            self.dropout2 = nn.Dropout(dropout_ratio2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x) #initial\n",
        "        if hasattr(self, 'activation1'):\n",
        "            x = self.activation1(x) #initial\n",
        "        if hasattr(self, 'batchnorm1'):\n",
        "            x = self.batchnorm1(x)\n",
        "        if hasattr(self, 'dropout1'):\n",
        "            x = self.dropout1(x)\n",
        "        x = self.fc2(x) #initial\n",
        "        if hasattr(self, 'activation2'):\n",
        "            x = self.activation2(x)\n",
        "        if hasattr(self, 'batchnorm2'):\n",
        "            x = self.batchnorm2(x)\n",
        "        if hasattr(self, 'dropout2'):\n",
        "            x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def train_linearizing_encoding_model(network, train_dataloader, train_targets, val_dataloader, val_targets, num_epochs, batch_size, loss_function, optimizer, learning_rate, save_name=None, patience=3):\n",
        "    criterion = loss_function\n",
        "    optimizer = optimizer(network.parameters(), lr=learning_rate)\n",
        "    network.train()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch = 0\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        training_loss = 0.0\n",
        "        for index, data in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "\n",
        "            inputs = data.to(device)\n",
        "            inputs = feature_extractor(inputs)\n",
        "            inputs = inputs.view(inputs.size(0), -1)\n",
        "\n",
        "\n",
        "            #targets = torch.zeros(inputs.size(0), output_dim).to(device)  # Change target dimension to output_dim\n",
        "            targets_batch = torch.tensor(train_targets[index*batch_size : index*batch_size + batch_size if index+batch_size <= train_targets.shape[0] else train_targets.shape[0]-index*batch_size]).to(device)\n",
        "            #print(index*batch_size, index*batch_size + batch_size)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = network(inputs)\n",
        "            loss = criterion(outputs, targets_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()\n",
        "\n",
        "        training_loss /= len(train_dataloader)\n",
        "        train_losses.append(training_loss)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {training_loss:.4f}')\n",
        "\n",
        "        network.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for index, data in enumerate(val_dataloader):\n",
        "                inputs = data.to(device)\n",
        "                inputs = feature_extractor(inputs)\n",
        "                inputs = inputs.view(inputs.size(0), -1)\n",
        "\n",
        "                targets_batch = torch.tensor(val_targets[index * batch_size: (index + 1) * batch_size]).to(device)\n",
        "\n",
        "                outputs = network(inputs)\n",
        "                loss = criterion(outputs, targets_batch)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_dataloader)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'Validation - Epoch {epoch + 1}/{num_epochs}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Check if the current validation loss is the best so far\n",
        "        if round(val_loss, 2) < round(best_val_loss, 2):\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        # Check if early stopping criterion is met\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f'Early stopping triggered. No improvement in {patience} epochs.')\n",
        "            break\n",
        "\n",
        "    if save_name:\n",
        "        torch.save(network.state_dict(), save_name+'.pt')\n",
        "\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnwMwyubT3Tk"
      },
      "source": [
        "#Hyperparameter Tuning with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5_tSH1n84G1",
        "outputId": "004680e4-33d2-46fc-d5b4-ccfdc9d70827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 12:15:31,145] A new study created in memory with name: no-name-dd28318f-89e9-4a56-94bb-6d4e5338e67b\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.activation.ReLU'> which is of type type.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.nn.modules.activation.Tanh'> which is of type type.\n",
            "  warnings.warn(message)\n",
            "<ipython-input-12-70e588f0ed83>:23: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_ratio1 = trial.suggest_uniform(\"dropout_ratio1\", 0.0, 0.5)\n",
            "<ipython-input-12-70e588f0ed83>:25: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_ratio2 = trial.suggest_uniform(\"dropout_ratio2\", 0.0, 0.5)\n",
            "<ipython-input-12-70e588f0ed83>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.adam.Adam'> which is of type type.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class 'torch.optim.sgd.SGD'> which is of type type.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Training Loss: 0.6870\n",
            "Validation - Epoch 1/3, Validation Loss: 0.4830\n",
            "Epoch 2/3, Training Loss: 0.4631\n",
            "Validation - Epoch 2/3, Validation Loss: 0.4541\n",
            "Epoch 3/3, Training Loss: 0.4498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 12:26:00,122] Trial 0 finished with value: 0.4497518594066302 and parameters: {'batch_size': 150, 'hidden_dim1': 155, 'hidden_dim2': 53, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.Tanh'>, 'bnorm1': True, 'bnorm2': True, 'dropout1': True, 'dropout_ratio1': 0.3861153052639878, 'dropout2': True, 'dropout_ratio2': 0.18215089186979622, 'learning_rate': 0.0005554173532824683, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.4497\n",
            "Epoch 1/3, Training Loss: 0.6986\n",
            "Validation - Epoch 1/3, Validation Loss: 0.6379\n",
            "Epoch 2/3, Training Loss: 1.1860\n",
            "Validation - Epoch 2/3, Validation Loss: 0.8777\n",
            "Epoch 3/3, Training Loss: 0.7753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 12:36:18,847] Trial 1 finished with value: 0.7753406713406245 and parameters: {'batch_size': 150, 'hidden_dim1': 241, 'hidden_dim2': 118, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': False, 'bnorm2': True, 'dropout1': False, 'dropout_ratio1': 0.29256293199133454, 'dropout2': True, 'dropout_ratio2': 0.10894141018599801, 'learning_rate': 0.09162672224547891, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.7057\n",
            "Epoch 1/3, Training Loss: 0.8341\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5609\n",
            "Epoch 2/3, Training Loss: 0.5269\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5920\n",
            "Epoch 3/3, Training Loss: 0.5360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 12:46:29,847] Trial 2 finished with value: 0.5359674145778021 and parameters: {'batch_size': 150, 'hidden_dim1': 565, 'hidden_dim2': 45, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.Tanh'>, 'bnorm1': False, 'bnorm2': False, 'dropout1': False, 'dropout_ratio1': 0.22832029701436313, 'dropout2': False, 'dropout_ratio2': 0.1616875511504542, 'learning_rate': 0.08714310657529234, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.6128\n",
            "Epoch 1/3, Training Loss: 0.5295\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5252\n",
            "Epoch 2/3, Training Loss: 0.5229\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5251\n",
            "Epoch 3/3, Training Loss: 0.5228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 12:56:54,066] Trial 3 finished with value: 0.5227948983510335 and parameters: {'batch_size': 150, 'hidden_dim1': 373, 'hidden_dim2': 25, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': False, 'bnorm2': False, 'dropout1': True, 'dropout_ratio1': 0.4579320134437364, 'dropout2': True, 'dropout_ratio2': 0.02170159309245112, 'learning_rate': 4.668069854824824e-05, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5250\n",
            "Epoch 1/3, Training Loss: 0.5183\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5113\n",
            "Epoch 2/3, Training Loss: 0.5087\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5109\n",
            "Epoch 3/3, Training Loss: 0.5085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:07:17,502] Trial 4 finished with value: 0.5084914450844129 and parameters: {'batch_size': 150, 'hidden_dim1': 491, 'hidden_dim2': 52, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.ReLU'>, 'activation2': <class 'torch.nn.modules.activation.Tanh'>, 'bnorm1': False, 'bnorm2': False, 'dropout1': True, 'dropout_ratio1': 0.4801581011222472, 'dropout2': True, 'dropout_ratio2': 0.4610215926380868, 'learning_rate': 1.010549930694834e-05, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5107\n",
            "Epoch 1/3, Training Loss: 0.5115\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5099\n",
            "Epoch 2/3, Training Loss: 0.5073\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5091\n",
            "Epoch 3/3, Training Loss: 0.5067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:17:40,174] Trial 5 finished with value: 0.5066520874698957 and parameters: {'batch_size': 150, 'hidden_dim1': 398, 'hidden_dim2': 130, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': False, 'bnorm2': False, 'dropout1': True, 'dropout_ratio1': 0.36525276151080455, 'dropout2': False, 'dropout_ratio2': 0.47071524661801933, 'learning_rate': 0.006044678842679579, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5086\n",
            "Epoch 1/3, Training Loss: 0.9380\n",
            "Validation - Epoch 1/3, Validation Loss: 0.7948\n",
            "Epoch 2/3, Training Loss: 0.6385\n",
            "Validation - Epoch 2/3, Validation Loss: 0.6140\n",
            "Epoch 3/3, Training Loss: 0.5968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:28:01,096] Trial 6 finished with value: 0.5967582374811172 and parameters: {'batch_size': 150, 'hidden_dim1': 445, 'hidden_dim2': 46, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': True, 'bnorm2': True, 'dropout1': True, 'dropout_ratio1': 0.06512706855733147, 'dropout2': True, 'dropout_ratio2': 0.2419851314813895, 'learning_rate': 3.222012383111736e-05, 'optimizer': <class 'torch.optim.adam.Adam'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5853\n",
            "Epoch 1/3, Training Loss: 0.5572\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5512\n",
            "Epoch 2/3, Training Loss: 0.5477\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5492\n",
            "Epoch 3/3, Training Loss: 0.5458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:38:28,435] Trial 7 finished with value: 0.5457790940999985 and parameters: {'batch_size': 150, 'hidden_dim1': 857, 'hidden_dim2': 326, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.ReLU'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': True, 'bnorm2': False, 'dropout1': False, 'dropout_ratio1': 0.45940660757517016, 'dropout2': False, 'dropout_ratio2': 0.13691497090556254, 'learning_rate': 0.0002540393697918865, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5474\n",
            "Epoch 1/3, Training Loss: 0.5577\n",
            "Validation - Epoch 1/3, Validation Loss: 0.5357\n",
            "Epoch 2/3, Training Loss: 0.5079\n",
            "Validation - Epoch 2/3, Validation Loss: 0.5086\n",
            "Epoch 3/3, Training Loss: 0.5062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:48:53,310] Trial 8 finished with value: 0.5061940461397171 and parameters: {'batch_size': 150, 'hidden_dim1': 441, 'hidden_dim2': 79, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.ReLU'>, 'activation2': <class 'torch.nn.modules.activation.ReLU'>, 'bnorm1': True, 'bnorm2': False, 'dropout1': False, 'dropout_ratio1': 0.4808964733466174, 'dropout2': True, 'dropout_ratio2': 0.3245507484827267, 'learning_rate': 0.0681762060257759, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5084\n",
            "Epoch 1/3, Training Loss: 0.8184\n",
            "Validation - Epoch 1/3, Validation Loss: 0.7821\n",
            "Epoch 2/3, Training Loss: 1.7987\n",
            "Validation - Epoch 2/3, Validation Loss: 0.6552\n",
            "Epoch 3/3, Training Loss: 0.6012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-07-05 13:59:18,987] Trial 9 finished with value: 0.6012042750914891 and parameters: {'batch_size': 150, 'hidden_dim1': 128, 'hidden_dim2': 40, 'num_epochs': 3, 'activation1': <class 'torch.nn.modules.activation.Tanh'>, 'activation2': <class 'torch.nn.modules.activation.Tanh'>, 'bnorm1': False, 'bnorm2': True, 'dropout1': False, 'dropout_ratio1': 0.22553558257565942, 'dropout2': False, 'dropout_ratio2': 0.0055179588701198545, 'learning_rate': 0.06331878363042374, 'optimizer': <class 'torch.optim.sgd.SGD'>}. Best is trial 0 with value: 0.4497518594066302.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation - Epoch 3/3, Validation Loss: 0.5570\n"
          ]
        }
      ],
      "source": [
        "#Train and validation targets\n",
        "lh_fmri_train = lh_fmri[idxs_train]\n",
        "lh_fmri_val = lh_fmri[idxs_val]\n",
        "\n",
        "with torch.no_grad():\n",
        "    sample_input = torch.zeros(1, 3, 224, 224).to(device)\n",
        "    output = feature_extractor(sample_input)\n",
        "\n",
        "input_dim = output.shape[1] # Set the dimensions for input and output of thr pretrained model\n",
        "output_dim = lh_fmri_train.shape[1]\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [150])\n",
        "    hidden_dim1 = trial.suggest_int(\"hidden_dim1\", int(input_dim/16), int(input_dim/2) , log=True)\n",
        "    hidden_dim2 = trial.suggest_int(\"hidden_dim2\", int(hidden_dim1/16), int(hidden_dim1/2) , log=True)\n",
        "    num_epochs = trial.suggest_categorical(\"num_epochs\", [3])\n",
        "    activation1 = trial.suggest_categorical(\"activation1\", [nn.ReLU,  nn.Tanh])\n",
        "    activation2 = trial.suggest_categorical(\"activation2\", [nn.ReLU,  nn.Tanh])\n",
        "    bnorm1 = trial.suggest_categorical(\"bnorm1\", [True, False])\n",
        "    bnorm2 = trial.suggest_categorical(\"bnorm2\", [True, False])\n",
        "    dropout1 = trial.suggest_categorical(\"dropout1\", [True, False])\n",
        "    dropout_ratio1 = trial.suggest_uniform(\"dropout_ratio1\", 0.0, 0.5)\n",
        "    dropout2 = trial.suggest_categorical(\"dropout2\", [True, False])\n",
        "    dropout_ratio2 = trial.suggest_uniform(\"dropout_ratio2\", 0.0, 0.5)\n",
        "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
        "    optimizer = trial.suggest_categorical(\"optimizer\", [optim.Adam, optim.SGD])\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "    train_imgs_paths = sorted(list(Path(train_img_dir).iterdir()))\n",
        "    test_imgs_paths = sorted(list(Path(test_img_dir).iterdir()))\n",
        "    train_imgs_dataloader = DataLoader(\n",
        "        ImageDataset(train_imgs_paths, idxs_train, transform),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    val_imgs_dataloader = DataLoader(\n",
        "        ImageDataset(train_imgs_paths, idxs_val, transform),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "\n",
        "    # Train the dimensionality reduction network\n",
        "    network = LinearizingEncodingModel(input_dim, output_dim, hidden_dim1,  hidden_dim2, activation1, activation2, bnorm1, bnorm2, dropout1, dropout_ratio1, dropout2, dropout_ratio2).to(device)\n",
        "    return train_linearizing_encoding_model(network, train_imgs_dataloader, lh_fmri_train, val_imgs_dataloader, lh_fmri_val, num_epochs, batch_size, loss_function, optimizer, learning_rate,  None, 3 )[0][-1]\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}